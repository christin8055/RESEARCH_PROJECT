{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b075ba18-8b73-45dd-8ea3-1fedaadde6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import metrics\n",
    "from keras import regularizers\n",
    "import math\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aedbc78-ee85-4467-8ae3-b9b50fe51067",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file=open(\"D:/VIT/CAPSTONE/FINAL/DATASET/DEFECT_PARTS_LABELLED/PICKLE_FILES/x_train.pickle\",\"rb\")\n",
    "x_train=pickle.load(pickle_file)\n",
    "pickle_file.close()\n",
    "\n",
    "pickle_file=open(\"D:/VIT/CAPSTONE/FINAL/DATASET/DEFECT_PARTS_LABELLED/PICKLE_FILES/y_train.pickle\",\"rb\")\n",
    "y_train=pickle.load(pickle_file)\n",
    "pickle_file.close()\n",
    "\n",
    "y_train_new=[]\n",
    "for y in y_train:\n",
    "  y=y[...,np.newaxis]\n",
    "  y_train_new.append(y)\n",
    "y_train=np.array(y_train_new).astype(int)\n",
    "\n",
    "x_train=x_train/255.0\n",
    "y_train=((y_train)//2.0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47047330-b785-4d87-921f-9baf76dcbaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x_train,y_train,test_size=0.4,shuffle=True,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e68961f-461e-4174-985e-279bd7cfea7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_conv_block(x, n_filters):\n",
    "   x = layers.Conv2D(n_filters, 3, padding = \"same\", activation = \"LeakyReLU\", kernel_regularizer=regularizers.l2(0.0001))(x)\n",
    "   x = layers.Conv2D(n_filters, 3, padding = \"same\", activation = \"LeakyReLU\")(x)\n",
    "   return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8cddda-178f-4f89-9e9b-869bda048660",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_block(x, n_filters):\n",
    "   f = double_conv_block(x, n_filters)\n",
    "   p = layers.MaxPool2D(2)(f)\n",
    "   p = layers.Dropout(0.2)(p)\n",
    "   return f, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cefaeff-db25-4f6f-bef9-cfad32387a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample_block(x, conv_features, n_filters):\n",
    "   x = layers.Conv2DTranspose(n_filters, 3, 2, padding=\"same\")(x)\n",
    "\n",
    "   x = layers.concatenate([x, conv_features])\n",
    "\n",
    "   x = layers.Dropout(0.4)(x)\n",
    "\n",
    "   x = double_conv_block(x, n_filters)\n",
    "\n",
    "   return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929e5b0d-8d07-45e0-9725-61a19aaee6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "@keras.saving.register_keras_serializable()\n",
    "class MaxPoolingWithArgmax2D(Layer):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            pool_size=(2, 2),\n",
    "            strides=(2, 2),\n",
    "            padding='same',\n",
    "            **kwargs):\n",
    "        super(MaxPoolingWithArgmax2D, self).__init__(**kwargs)\n",
    "        self.padding = padding\n",
    "        self.pool_size = pool_size\n",
    "        self.strides = strides\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        padding = self.padding\n",
    "        pool_size = self.pool_size\n",
    "        strides = self.strides\n",
    "        ksize = [1, *pool_size, 1]\n",
    "        padding = padding.upper()\n",
    "        strides = [1, *strides, 1]\n",
    "        output, argmax = tf.nn.max_pool_with_argmax(\n",
    "            inputs,\n",
    "            ksize=ksize,\n",
    "            strides=strides,\n",
    "            padding=padding)\n",
    "\n",
    "        argmax = K.cast(argmax, K.floatx())\n",
    "        return [output, argmax]\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        ratio = (1, 2, 2, 1)\n",
    "        output_shape = [\n",
    "            dim // ratio[idx]\n",
    "            if dim is not None else None\n",
    "            for idx, dim in enumerate(input_shape)]\n",
    "        output_shape = tuple(output_shape)\n",
    "        return [output_shape, output_shape]\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return 2 * [None]\n",
    "\n",
    "@keras.saving.register_keras_serializable()\n",
    "class MaxUnpooling2D(Layer):\n",
    "    def __init__(self, size=(2, 2), **kwargs):\n",
    "        super(MaxUnpooling2D, self).__init__(**kwargs)\n",
    "        self.size = size\n",
    "\n",
    "    def call(self, inputs, output_shape=None):\n",
    "        updates, mask = inputs[0], inputs[1]\n",
    "        mask = K.cast(mask, 'int32')\n",
    "        input_shape = tf.shape(updates, out_type='int32')\n",
    "\n",
    "        if output_shape is None:\n",
    "            output_shape = (\n",
    "                input_shape[0],\n",
    "                input_shape[1] * self.size[0],\n",
    "                input_shape[2] * self.size[1],\n",
    "                input_shape[3])\n",
    "\n",
    "        ret = tf.scatter_nd(K.expand_dims(K.flatten(mask)),\n",
    "                            K.flatten(updates),\n",
    "                            [K.prod(output_shape)])\n",
    "\n",
    "        input_shape = updates.shape\n",
    "        out_shape = [-1,\n",
    "                     input_shape[1] * self.size[0],\n",
    "                     input_shape[2] * self.size[1],\n",
    "                     input_shape[3]]\n",
    "        return K.reshape(ret, out_shape)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        mask_shape = input_shape[1]\n",
    "        return (\n",
    "            mask_shape[0],\n",
    "            mask_shape[1] * self.size[0],\n",
    "            mask_shape[2] * self.size[1],\n",
    "            mask_shape[3]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75aa54ba-4591-4f35-b569-cf70fd9b54c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "  # inputs\n",
    "  inputs = layers.Input(shape=(256,256,3))\n",
    "\n",
    "  f1, p1 = downsample_block(inputs, 32)\n",
    "\n",
    "  f2, p2 = downsample_block(p1, 64)\n",
    "\n",
    "  pool_1, mask_1 = MaxPoolingWithArgmax2D(pool_size=(2, 2))(p2)\n",
    "\n",
    "  unpool_1 = MaxUnpooling2D(size=(2, 2))([pool_1, mask_1])\n",
    "\n",
    "  u8 = upsample_block(unpool_1, f2, 64)\n",
    "\n",
    "  u9 = upsample_block(u8, f1, 32)\n",
    "\n",
    "  outputs = layers.Conv2D(1, 1, padding=\"same\", activation = \"softmax\")(u9)\n",
    "\n",
    "\n",
    "    \n",
    "  unet_model = tf.keras.Model(inputs, outputs, name=\"U-Net\")\n",
    "\n",
    "  return unet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8dba7a-74b9-4337-b930-7b9ea3388797",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=build_model()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1c8e37-5f40-49fb-b348-9d862b18e83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"Adam\",loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "\n",
    "checkpoint_filepath =\"D:/VIT/CAPSTONE/FINAL/MODEL_BACKUP/model_1.h5\"\n",
    "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath,monitor='accuracy',mode='max',save_best_only=True)\n",
    "\n",
    "model_history = model.fit(x_train,y_train,epochs=100,batch_size=64,callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47438a1-981e-4721-8bc6-468b4ca1dcd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone_3_8_64",
   "language": "python",
   "name": "capstone_3_8_64"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
